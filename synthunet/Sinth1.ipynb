{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Sinth1.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#Master Thesis\n",
    "#Sinth1 _ Trial 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Dataset Selection, loading and preprocessing "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %cd 'drive/My Drive'\n",
    "# %cd 'Thesis/Code'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip3 install https://nic.udg.edu/niclib/wheels/niclib-1.0b0-py3-none-any.whl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import niclib as nl\n",
    "import time\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "day = nl.get_timestamp(time_format = '%d_%m_%Y')\n",
    "whm_small = False\n",
    "if whm_small:\n",
    "  challenge ='Wmh_small'\n",
    "  data_path = '/home/pierpaolo/Datasets/WHM_small'\n",
    "\n",
    "else:\n",
    "  challenge ='Wmh_big_trial2'\n",
    "  data_path = '/home/pierpaolo/Datasets/WMH20173D'\n",
    "\n",
    "mainfolder = nl.make_dir(day +'_'+challenge)\n",
    "checkpoints_path = nl.make_dir(os.path.join(mainfolder,'checkpoints/'))\n",
    "results_path = nl.make_dir(os.path.join(mainfolder,'results/'))\n",
    "metrics_path = nl.make_dir(os.path.join(mainfolder,'metrics/'))\n",
    "log_path = nl.make_dir(os.path.join(mainfolder,'log/'))\n",
    "\n",
    "case_paths = [f.path for f in os.scandir(data_path) if f.is_dir()]\n",
    "if whm_small:\n",
    "  case_paths, test_case_paths = case_paths[:-3], case_paths[-3:] # Set aside 3 images for testing\n",
    "else:\n",
    "  case_paths, test_case_paths = case_paths[:-5], case_paths[-5:]\n",
    "\n",
    "print(\"Loading training dataset with {} images...\".format(len(case_paths)))\n",
    "if challenge =='small':\n",
    "  def load_case(case_path):\n",
    "      #Dictionary containing at first the img and the gt\n",
    "      t1_nifti = nib.load(os.path.join(case_path, 'T1_brain.nii.gz'))\n",
    "      t1_img = (t1_nifti.get_data())\n",
    "      t1_img = nl.data.clip_percentile(t1_img, [0.0, 99.99])  # Clip to ignore bright extrema\n",
    "      t1_img = nl.data.adjust_range(t1_img, [0.0, 255.0]) # Adjust range to 0-1 for Sigmoid activation\n",
    "      wmh_nifti =nib.load(os.path.join(case_path,'wmh.nii.gz'))\n",
    "      wmh_img = (wmh_nifti.get_data())\n",
    "      wmh_img = nl.data.clip_percentile(wmh_img, [0.0, 99.99])  # Clip to ignore bright extrema\n",
    "      wmh_img = nl.data.adjust_range(wmh_img, [0.0, 255.0]) # Adjust range to 0-1 for Sigmoid activation\n",
    "      ob = np.stack([t1_img, wmh_img],axis=0)\n",
    "      gt_nifti = nib.load(os.path.join(case_path, 'FLAIR_brain.nii.gz'))\n",
    "      gt_img = np.expand_dims(gt_nifti.get_data(), axis=0)\n",
    "      gt_img = nl.data.clip_percentile(gt_img, [0.0, 99.99])  # Clip to ignore bright extrema\n",
    "      gt_img = nl.data.adjust_range(gt_img, [0.0, 255.0]) # Adjust range to 0-1 for Sigmoid activation\n",
    "      return {'id' : case_path.split('/')[-1], 'nifiti': t1_nifti, 't1': ob, 'flair': gt_img}\n",
    "else:\n",
    "  def load_case(case_path):\n",
    "    #Dictionary containing at first the img and the gt\n",
    "    t1_nifti = nib.load(os.path.join(case_path, '3DT1_brain.nii.gz'))\n",
    "    t1_img = (t1_nifti.get_data())\n",
    "    t1_img = nl.data.clip_percentile(t1_img, [0.0, 99.99])  # Clip to ignore bright extrema\n",
    "    t1_img = nl.data.adjust_range(t1_img, [0.0, 255.0]) # Adjust range to 0-1 for Sigmoid activation\n",
    "    t1_img = np.expand_dims(t1_nifti.get_data(), axis=0) # Add single channel modality\n",
    "#     wmh_nifti =nib.load(os.path.join(case_path,'3DWMH.nii.gz'))\n",
    "#     wmh_img = (wmh_nifti.get_data())\n",
    "#     ob = np.stack([t1_img, wmh_img],axis =0)\n",
    "    ob = t1_img\n",
    "    gt_nifti = nib.load(os.path.join(case_path, '3DFLAIR_brain.nii.gz'))\n",
    "    gt_img = np.expand_dims(gt_nifti.get_data(), axis=0)\n",
    "    gt_img = nl.data.clip_percentile(gt_img, [0.0, 99.99])  # Clip to ignore bright extrema\n",
    "    gt_img = nl.data.adjust_range(gt_img, [0.0, 255.0]) # Adjust range to 0-1 for Sigmoid activation\n",
    "    return {'id' : case_path.split('/')[-1], 'nifiti': t1_nifti, 't1': ob, 'flair': gt_img}\n",
    "\n",
    "dataset = nl.parallel_load(load_func=load_case, arguments=case_paths, num_workers=12)\n",
    "dataset_train, dataset_val = nl.split_list(dataset, fraction=0.8) # Split images into train and validation\n",
    "print('Training dataset with {} train and {} val images'.format(len(dataset_train), len(dataset_val)))\n",
    "# print('Dim of input:', len(dataset_train))\n",
    "\n",
    "\n",
    "### 2. Create training and validation patch generators\n",
    "#-----Not Needed---------\n",
    "# train_sampling = nl.generator.BalancedSampling(\n",
    "#     labels=[np.argmax(case['flair'], axis=0) for case in dataset_train],\n",
    "#     num_patches=1000 * len(dataset_train))\n",
    "#------------------------------\n",
    "step = 1\n",
    "samples = 500\n",
    "train_patch_set = nl.generator.ZipSet([\n",
    "    nl.generator.PatchSet(\n",
    "        images=[case['t1'] for case in dataset_train],\n",
    "        patch_shape=(32, 32, 32),\n",
    "        normalize='none',\n",
    "        sampling=nl.generator.UniformSampling((step,step,step), num_patches=samples * len(dataset_train))),\n",
    "    nl.generator.PatchSet(\n",
    "        images=[case['flair'] for case in dataset_train],\n",
    "        patch_shape=(32, 32, 32),\n",
    "        normalize='none',\n",
    "        sampling=nl.generator.UniformSampling((step,step,step), num_patches=samples * len(dataset_train)))])\n",
    "\n",
    "# val_sampling = nl.generator.BalancedSampling(\n",
    "#     labels=[np.argmax(case['flair'], axis=0) for case in dataset_val],\n",
    "#     num_patches=1000 * len(dataset_val))\n",
    "\n",
    "val_patch_set = nl.generator.ZipSet([\n",
    "    nl.generator.PatchSet(\n",
    "        images=[case['t1'] for case in dataset_val],\n",
    "        patch_shape=(32, 32, 32),\n",
    "        normalize='none',\n",
    "        sampling=nl.generator.UniformSampling((step,step,step), num_patches=samples * len(dataset_val))),\n",
    "    nl.generator.PatchSet(\n",
    "        images=[case['flair'] for case in dataset_val],\n",
    "        patch_shape=(32, 32, 32),\n",
    "        normalize='none',\n",
    "        sampling=nl.generator.UniformSampling((step,step,step), num_patches=samples * len(dataset_val)))])\n",
    "        \n",
    "        \n",
    "class Unet(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic U-net model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, output_size):\n",
    "\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        # conv1 down\n",
    "        self.conv1 = nn.Conv3d(in_channels=input_size,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # max-pool 1\n",
    "        self.pool1 = nn.Conv3d(in_channels=32,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=2,\n",
    "                               stride=2)\n",
    "        # conv2 down\n",
    "        self.conv2 = nn.Conv3d(in_channels=32,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # max-pool 2\n",
    "        self.pool2 = nn.Conv3d(in_channels=64,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=2,\n",
    "                               stride=2)\n",
    "        # conv3 down\n",
    "        self.conv3 = nn.Conv3d(in_channels=64,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # max-pool 3\n",
    "        self.pool3 = nn.Conv3d(in_channels=128,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=2,\n",
    "                               stride=2)\n",
    "        # conv4 down (latent space)\n",
    "        self.conv4 = nn.Conv3d(in_channels=128,\n",
    "                               out_channels=256,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # up-sample conv4\n",
    "        self.up1 = nn.ConvTranspose3d(in_channels=256,\n",
    "                                      out_channels=128,\n",
    "                                      kernel_size=2,\n",
    "                                      stride=2)        \n",
    "        # conv 5 (add up1 + conv3)\n",
    "        self.conv5 = nn.Conv3d(in_channels=128,\n",
    "                               out_channels=128,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # up-sample conv5\n",
    "        self.up2 = nn.ConvTranspose3d(in_channels=128,\n",
    "                                      out_channels=64,\n",
    "                                      kernel_size=2,\n",
    "                                      stride=2)\n",
    "        # conv6 (add up2 + conv2) \n",
    "        self.conv6 = nn.Conv3d(in_channels=64,\n",
    "                               out_channels=64,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # up 3\n",
    "        self.up3 = nn.ConvTranspose3d(in_channels=64,\n",
    "                                      out_channels=32,\n",
    "                                      kernel_size=2,\n",
    "                                      stride=2)\n",
    "        # conv7 (add up3 + conv1)\n",
    "        self.conv7 = nn.Conv3d(in_channels=32,\n",
    "                               out_channels=32,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        # conv8 (classification)\n",
    "        self.conv8 = nn.Conv3d(in_channels=32,\n",
    "                               out_channels=output_size,\n",
    "                               kernel_size=1)\n",
    "    def forward(self, x):\n",
    "\n",
    "            # encoder\n",
    "            x1 = F.relu(self.conv1(x))\n",
    "            x1p = self.pool1(x1)\n",
    "            x2 = F.relu(self.conv2(x1p))\n",
    "            x2p = self.pool2(x2)\n",
    "            x3 = F.relu(self.conv3(x2p))\n",
    "            x3p = self.pool3(x3)\n",
    "            \n",
    "            # latent space\n",
    "            x4 = F.relu(self.conv4(x3p))\n",
    "\n",
    "            # decoder\n",
    "            up1 = self.up1(x4)\n",
    "            x5 = F.relu(self.conv5(up1 + x3)) # look how layers are added :o\n",
    "            up2 = self.up2(x5)\n",
    "            x6 = F.relu(self.conv6(up2 + x2))\n",
    "            up3 = self.up3(x6)\n",
    "            x7 = F.relu(self.conv7(up3 + x1))\n",
    "            \n",
    "            # output layer (1 classes)\n",
    "            out = self.conv8(x7)\n",
    "            return out\n",
    "            \n",
    "model = ResUNet(outputsize=1, inputsize=1, k=16)\n",
    "\n",
    "name = 'ResUNet50_2'\n",
    "name2 = '_full_wmh_net.pt'\n",
    "fullname = name+name2\n",
    "trainer = nl.net.train.Trainer(\n",
    "    max_epochs=50,\n",
    "    loss_func=nn.L1Loss(),\n",
    "    optimizer=torch.optim.Adadelta,\n",
    "    optimizer_opts={'lr': 1.0},\n",
    "    train_metrics={'l1': nn.L1Loss()},\n",
    "    val_metrics={'l1': nn.L1Loss()},\n",
    "    plugins=[\n",
    "        nl.net.train.ProgressBar(),\n",
    "        nl.net.train.ModelCheckpoint(checkpoints_path + fullname, save='best', metric_name='loss', mode='min'),\n",
    "        nl.net.train.EarlyStopping(metric_name='loss', mode='min', patience=10),\n",
    "        nl.net.train.Logger(log_path + 'train_log.csv')],\n",
    "    device='cuda')\n",
    "\n",
    "trainer.train(model, train_gen, val_gen)\n",
    "unet_trained = torch.load(checkpoints_path + fullname)\n",
    "\n",
    "predictor = nl.net.test.PatchTester(\n",
    "    patch_shape=(2, 32, 32, 32),\n",
    "    patch_out_shape=(1, 32, 32, 32),\n",
    "    extraction_step=(16, 16, 16),\n",
    "    normalize='none',\n",
    "    activation=None)\n",
    "    \n",
    "dataset_test = nl.parallel_load(load_func=load_case, arguments=test_case_paths, num_workers=12)\n",
    "synthetic_images  = []\n",
    "for n, case in enumerate(dataset_test):\n",
    "  #Idea: show the img in imput for testing\n",
    "    a = np.squeeze(case['flair'])\n",
    "    # plt.imshow(a[:,:,33])\n",
    "    # Predict image with the predictor and store\n",
    "    print(\"Synthetising image {}\".format(n))\n",
    "    synth_img = predictor.predict(unet_trained, case['t1'])\n",
    "    b = np.squeeze(synth_img)\n",
    "    plt.figure(1, figsize=(7,7))\n",
    "    plt.subplot(221)\n",
    "    plt.imshow(a[:,:,48], cmap ='gray')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    plt.imshow(b[:,:,48], cmap = 'gray')\n",
    "    plt.subplot(223)\n",
    "    plt.imshow(a[:,:,39], cmap ='gray')\n",
    "\n",
    "    plt.subplot(224)\n",
    "    plt.imshow(b[:,:,39], cmap = 'gray')\n",
    "    plt.show()\n",
    "    #plt.show(tissue_probabilities[0,:,:,20])\n",
    "    namei = name[0:6]\n",
    "    nl.save_nifti(\n",
    "        filepath=results_path + name+'_img_{}_synthetic.nii.gz'.format(case['id']),\n",
    "        volume=np.squeeze(synth_img,axis =0), # Remove single channel dimension for storage\n",
    "        reference=case['nifiti']\n",
    "        #channel_handling='split'\n",
    "        )\n",
    "\n",
    "    # Add the input and output images to a list for metrics computation\n",
    "    synthetic_images.append(synth_img)                        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}